name: Scrape Mega TV Episodes

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Base domain URL (e.g., https://www.megatv.com)'
        required: true
        type: string
        default: 'https://www.megatv.com'
      base_url:
        description: 'Base URL to scrape episodes from'
        required: true
        type: string
        default: '/episodes/'
      query_string:
        description: 'Query string part of the URL'
        required: true
        type: string
        default: '?id=S102&type=tvshows'
      from_page:
        description: 'Starting page number'
        required: true
        type: string
        default: '1'
      to_page:
        description: 'Ending page number'
        required: true
        type: string
        default: '2'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: Run scraper
        run: |
          python scripts/scrape.py --domain "${{ github.event.inputs.domain }}" \
                                   --base-url "${{ github.event.inputs.base_url }}" \
                                   --query-string "${{ github.event.inputs.query_string }}" \
                                   --from-page "${{ github.event.inputs.from_page }}" \
                                   --to-page "${{ github.event.inputs.to_page }}"

      - name: Upload JSON file
        uses: actions/upload-artifact@v3
        with:
          name: series-json
          path: series.json
